
# ğŸ§  OpenAI Agents SDK

## ğŸ¯  Basic Agent Setup with Google Gemini API Key (Free)



## Step 1: Add Your OpenAI API Key

Before running your agent, you need to provide your Google **Gemini API** key so the SDK can connect.

### ğŸ§¾ 1. Create a .env file

Inside your project folder, create a new file named: **`.env`**

### ğŸ” 2. Add your API key

Open the .env file and add this line:
```bash
GEMINI_API_KEY=your_actual_api_key_here
```
Tips:
To Get API Key follow this Repo:
[Get Gemini Key](../../03_get_api_keys/02_gemini_api_key/)

### âš ï¸ Important:

- Never share your API key publicly or upload .env to GitHub.
- Add .env to your .gitignore file to keep it private.


<br>

## ğŸ’» Step 3: Writing Our First Agent

Now create a new file named **`main.py`** and paste the following code ğŸ‘‡

```python
from agents import Agent, Runner, OpenAIChatCompletionsModel, set_tracing_disabled
from openai import AsyncOpenAI
from dotenv import load_dotenv
import os

load_dotenv()
set_tracing_disabled(disabled=True)

my_api_key = os.getenv("GEMINI_API_KEY")

my_clinet = AsyncOpenAI(api_key=my_api_key, base_url="https://generativelanguage.googleapis.com/v1beta/openai/")

my_model = OpenAIChatCompletionsModel(model="gemini-2.5-flash", openai_client=my_clinet)

my_agent = Agent(
    name="Assistant",
    instructions="You are a helpful Assistant",
    model=my_model
)

my_prompt = "What is capital of Pakistan?"

my_result = Runner.run_sync(
    starting_agent=my_agent, input=my_prompt
)


print(f"\n{my_result.final_output}")
```
---
<br>

## ğŸ§© Step-by-Step Code Explanation

### 1ï¸âƒ£ Import Required Libraries

```python
from agents import Agent, Runner, OpenAIChatCompletionsModel, set_tracing_disabled
from openai import AsyncOpenAI
from dotenv import load_dotenv
import os
```

* **Agent** â†’ Creates your AI assistant (the brain).
* **Runner** â†’ Runs or executes the agent.
* **OpenAIChatCompletionsModel** â†’ Allows you to use any OpenAI-compatible model (like Gemini).
* **set_tracing_disabled** â†’ Turns off tracing (optional; makes execution faster).
* **AsyncOpenAI** â†’ Helps connect with OpenAI or any compatible API (like Gemini).
* **load_dotenv** â†’ Loads secret keys from `.env` file.
* **os** â†’ Used to access environment variables in Python.

---


### 2ï¸âƒ£ Load Environment Variables

```python
load_dotenv()
```

This loads the `.env` file where your API key is saved.

Example of `.env` file:

```
GEMINI_API_KEY=your_gemini_api_key_here
```

---

### 3ï¸âƒ£ Disable Tracing (Optional)

```python
set_tracing_disabled(disabled=True)
```

This line **turns off tracing**, which is useful if you donâ€™t want detailed logs or analytics.
You can skip this if you prefer default tracing behavior.

---

### 4ï¸âƒ£ Get API Key from Environment

```python
my_api_key = os.getenv("GEMINI_API_KEY")
```

* Fetches the **Gemini API key** from your `.env` file securely.
* Keeps your key hidden from public code.

---

### 5ï¸âƒ£ Create Gemini Client

```python
my_clinet = AsyncOpenAI(api_key=my_api_key, base_url="https://generativelanguage.googleapis.com/v1beta/openai/")
```

* Connects to **Geminiâ€™s API endpoint**.
* Uses `AsyncOpenAI` because Gemini API is **OpenAI-compatible**.
* `base_url` changes the default OpenAI endpoint to Geminiâ€™s URL.

---

### 6ï¸âƒ£ Define the Model

```python
my_model = OpenAIChatCompletionsModel(model="gemini-2.5-flash", openai_client=my_clinet)
```

* Tells the SDK which **Gemini model** you want to use.
* Here weâ€™re using **`gemini-2.5-flash`** â€” a fast and efficient model.
* `openai_client` links this model to the Gemini API connection.

---

### 7ï¸âƒ£ Create the Agent

```python
my_agent = Agent(
    name="Assistant",
    instructions="You are a helpful Assistant",
    model=my_model
)
```

* Creates a **custom AI agent** using the Gemini model.
* The `instructions` define how the assistant should behave.

---

### 8ï¸âƒ£ Add a Prompt

```python
my_prompt = "What is capital of Pakistan?"
```

* This is the question or command for your agent.

---

### 9ï¸âƒ£ Run the Agent

```python
my_result = Runner.run_sync(
    starting_agent=my_agent, input=my_prompt
)
```

* Runs the agent and waits for its response.
* The output (answer) is stored in `my_result`.

---

### ğŸ”Ÿ Print the Final Output

```python
print(f"\n{my_result.final_output}")
```

* Displays the final response from the Gemini model.

âœ… **Example Output:**

```
The capital of Pakistan is Islamabad.
```

---

## ğŸ§¾ Summary

âœ”ï¸ Added Gemini API key in `.env` file

âœ”ï¸ Connected Gemini API using `AsyncOpenAI`

âœ”ï¸ Used `OpenAIChatCompletionsModel` for Gemini models

âœ”ï¸ Created and ran an agent successfully

---


---

## ğŸ‰ You Did It!

Now your **OpenAI Agents SDK** project is successfully connected to **Google Gemini models**.
This lets you build **AI Agents** powered by Geminiâ€™s intelligence â€” fast, secure, and simple.

---

### ğŸ“º Course by: **IB Coding School**

> *Subscribe on YouTube for more practical lectures on the OpenAI Agents SDK full course.*

```

---



